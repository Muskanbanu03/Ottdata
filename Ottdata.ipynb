{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6xBlyBcMMux",
        "WRWiw-i3MVvU",
        "L9x-fnc9MzMC",
        "gZoOoze_O13b",
        "IBQq-eLrN6G2",
        "osVfkxrbPd7M",
        "i4ig7QIOPiA9",
        "Nd_IDR2uP8Br",
        "YCewD-UGQE0Q",
        "fiAQJUrHRM8F",
        "KAlmzBFoRYOg",
        "IKsCSaWcRp51",
        "9fpLoeGiRwgg",
        "hFePOZwVR1j7",
        "PYXOoB2vR7Fx",
        "vsIZhPD0dgAA",
        "kiG9mDYteE2p",
        "1THqC335b4Yi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNGPG7Br-qTi"
      },
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n",
        "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
        "</p></center>\n",
        "\n",
        "<center><font size=10>Predictive Modelling</center></font>\n",
        "<center><font size=6>Linear Regression </center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><font size=6>Over The Top(OTT) media channel</font></center>"
      ],
      "metadata": {
        "id": "MBzAE64CrJmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Problem statement**"
      ],
      "metadata": {
        "id": "X37fti51LB3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context**\n",
        "\n",
        "\n",
        "An over-the-top (OTT) media service is a media service offered directly to viewers via the internet. The term is most synonymous with subscription-based video-on-demand services that offer access to film and television content, including existing series acquired from other producers, as well as original content produced specifically for the service. They are typically accessed via websites on personal computers, apps on smartphones and tablets, or televisions with integrated Smart TV platforms.\n",
        "\n",
        "Presently, OTT services are at a relatively nascent stage and are widely accepted as a trending technology across the globe. With the increasing change in customers' social behavior, which is shifting from traditional subscriptions to broadcasting services and OTT on-demand video and music subscriptions every year, OTT streaming is expected to grow at a very fast pace. The global OTT market size was valued at $121.61  billion  in 2019  and is projected to reach $1,039.03 billion by 2027, growing at a CAGR of 29.4% from 2020 to 2027. The shift from television to OTT services for entertainment is driven by benefits such as on-demand services, ease of access, and access to better networks and digital connectivity.\n",
        "\n",
        "With the outbreak of COVID19, OTT services are striving to meet the growing entertainment appetite of viewers, with some platforms already experiencing a 46% increase in consumption and subscriber count as viewers seek fresh content. With innovations and advanced transformations, which will enable the customers to access everything they want in a single space, OTT platforms across the world are expected to increasingly attract subscribers on a concurrent basis.\n",
        "\n",
        "\n",
        "\n",
        "**objective**\n",
        "\n",
        "\n",
        "ShowTime is an OTT service provider and offers a wide variety of content (movies, web shows, etc.) for its users. They want to determine the driver variables for first-day content viewership so that they can take necessary measures to improve the viewership of the content on their platform. Some of the reasons for the decline in viewership of content would be the decline in the number of people coming to the platform, decreased marketing spend, content timing clashes, weekends and holidays, etc. They have hired you as a Data Scientist, shared the data of the current content in their platform, and asked you to analyze the data and come up with a linear regression model to determine the driving factors for first-day viewership.\n",
        "\n",
        "\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "\n",
        "The data contains the different factors to analyze for the content. The detailed data dictionary is given below.\n",
        "\n",
        "**Data Dictionary:**\n",
        "\n",
        "\n",
        "* visitors: Average number of visitors, in millions, to the platform in the past week\n",
        "* ad_impressions: Number of ad impressions, in millions, across all ad campaigns for the content (running and completed)\n",
        "* major_sports_event: Any major sports event on the day\n",
        "*genre: Genre of the content\n",
        "*dayofweek: Day of the release of the content\n",
        "*season: Season of the release of the content\n",
        "*views_trailer: Number of views, in millions, of the content trailer\n",
        "*views_content: Number of first-day views, in millions, of the content\n",
        "\n",
        "\n",
        "\n",
        "The following questions need to be answered as a part of the EDA section of the project:\n",
        "\n",
        "\n",
        "1)What does the distribution of content views look like?\n",
        "\n",
        "2)What does the distribution of genres look like?\n",
        "\n",
        "3)The day of the week on which content is released generally plays a key role in the viewership. How does the viewership vary with the day of release?\n",
        "\n",
        "4)How does the viewership vary with the season of release?\n",
        "\n",
        "5)What is the correlation between trailer views and content views?"
      ],
      "metadata": {
        "id": "3zu-I-h03c7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Installing and importing necessary libraries**"
      ],
      "metadata": {
        "id": "g6xBlyBcMMux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91oJB2Gs3YNP"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to build linear regression_model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# to check model performance\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loading dataset**"
      ],
      "metadata": {
        "id": "WRWiw-i3MVvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott=pd.read_csv('/content/ottdata.csv')"
      ],
      "metadata": {
        "id": "6fQVo6z5DVOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#**Data overview**"
      ],
      "metadata": {
        "id": "L9x-fnc9MzMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting first 5 rows"
      ],
      "metadata": {
        "id": "YP-kIr0rNMoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.head()"
      ],
      "metadata": {
        "id": "_GBYGJI7NRSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Above is the first 5 rows of the given dataset\n",
        "* visitors: Average number of visitors, in millions, to the platform in the past week\n",
        "* ad_impressions: Number of ad impressions, in millions, across all ad campaigns for the content (running and completed)\n",
        "* major_sports_event: Any major sports event on the day\n",
        "* genre: Genre of the content\n",
        "* dayofweek: Day of the release of the content\n",
        "* season: Season of the release of the content\n",
        "* views_trailer: Number of views, in millions, of the content trailer\n",
        "* views_content: Number of first-day views, in millions, of the content"
      ],
      "metadata": {
        "id": "UqlPr-9bccab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting last 5 rows of the dataset"
      ],
      "metadata": {
        "id": "FU_cB19-M4Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.tail()"
      ],
      "metadata": {
        "id": "sNYPHtpHJKOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking the datatype of every column"
      ],
      "metadata": {
        "id": "hTCbtSfzNVSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.info()"
      ],
      "metadata": {
        "id": "sbRnvUArJMbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 5 numeric columns(float-4 and int-1) and there are 3 string(object)columns in the dataset\n",
        "* The target variable is views_content , which of float type."
      ],
      "metadata": {
        "id": "ge2knOV0dx2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Looking at all the columns"
      ],
      "metadata": {
        "id": "ZkLsziDhNd9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.columns"
      ],
      "metadata": {
        "id": "dqxLjkDuJYYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Above are the columns of the dataset"
      ],
      "metadata": {
        "id": "uDIQ8TlPeYen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking the statistical summary of the dataset"
      ],
      "metadata": {
        "id": "0vQRZY_QNkHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.describe(include='all').T"
      ],
      "metadata": {
        "id": "1YbR_ukRJdmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Viewership of content is between 0.22 to 0.80.\n",
        "* Half of the viewership of content is 0.45.\n",
        "* 4 seasons are there\n",
        "* 8 types of genre is given\n",
        "* All the days of the week\n",
        "* Visitors are between 1 to 2"
      ],
      "metadata": {
        "id": "lWTgDTUEegMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott['visitors']=ott['visitors'].astype(float)"
      ],
      "metadata": {
        "id": "TtsmfFv1P5Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ott['ad_impressions']=ott['ad_impressions'].astype(float)"
      ],
      "metadata": {
        "id": "K1P6y-G6QSNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ott['visitors']=ott['visitors'].astype(int)"
      ],
      "metadata": {
        "id": "ZwPstUAqQgzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking the shape of the dataset"
      ],
      "metadata": {
        "id": "J21YB7Y2gHW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.shape"
      ],
      "metadata": {
        "id": "_rzDUjCtJhaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 1000 rows\n",
        "* 8 columns"
      ],
      "metadata": {
        "id": "knFmHDXYgL6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking whether there is null values"
      ],
      "metadata": {
        "id": "LrngJ8pigVel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.isnull().sum()"
      ],
      "metadata": {
        "id": "HFzCNznBJxwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is no null values found in the dataset"
      ],
      "metadata": {
        "id": "LKfoM6n7gcg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking for duplicate values in the dataset"
      ],
      "metadata": {
        "id": "PruaFb8pgitI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ott.duplicated().sum()"
      ],
      "metadata": {
        "id": "hhMLR1vxJ6MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is no duplicate values found in the dataset"
      ],
      "metadata": {
        "id": "qkJYoxj1gny-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a copy of the data so that original data remains the same\n",
        "data=ott.copy()"
      ],
      "metadata": {
        "id": "qTIx4QBCKAmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exploratory data analysis(EDA)**"
      ],
      "metadata": {
        "id": "gZoOoze_O13b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe4tCS5PCFZk"
      },
      "source": [
        "**The below functions need to be defined to carry out the EDA.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (15,10))\n",
        "    kde: whether to show the density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ],
      "metadata": {
        "id": "LT_RtCgXWZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 2, 6))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 2, 6))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        hue=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n],\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ],
      "metadata": {
        "id": "Q6qdxRDsWf8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Univariate Analysis"
      ],
      "metadata": {
        "id": "IBQq-eLrN6G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Views_content`"
      ],
      "metadata": {
        "id": "XKj89SYgOBir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,'views_content',bins=50);"
      ],
      "metadata": {
        "id": "6mBv4neuX-GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Viewership of content is slightly normally distributed with right tail\n",
        "* Average and the 50% of the viewership content is between 0.4 to 0.5."
      ],
      "metadata": {
        "id": "MLaVp4R2hlBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Visitors`"
      ],
      "metadata": {
        "id": "1Jd-uXMWOKxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,'visitors')"
      ],
      "metadata": {
        "id": "gj3JlkZOPASP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is a single outlier present in the visitors column\n",
        "* The mean and the median is at 1.7."
      ],
      "metadata": {
        "id": "gYQ4lIiIiOYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Ad_impression`"
      ],
      "metadata": {
        "id": "-x9VVqWAOTff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,'ad_impressions')"
      ],
      "metadata": {
        "id": "aKXGcjg5VuVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The distribution is right skewed\n",
        "* The median and the mean is near to 1400"
      ],
      "metadata": {
        "id": "5eLiHxcBisRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Major_sports_event`"
      ],
      "metadata": {
        "id": "t9it0ZjUOcJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,'major_sports_event')"
      ],
      "metadata": {
        "id": "cSXKB0PGXTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The major sports event contains only 2 columns that is 0 and 1.\n",
        "* The median of major sports event is 0.4."
      ],
      "metadata": {
        "id": "12y8-yykLiWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Views trailer`"
      ],
      "metadata": {
        "id": "54vhyFf0Ohwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,'views_trailer')"
      ],
      "metadata": {
        "id": "xvc9kzypbhqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The distribution of views trailer is highly right skewed with so many outliers in it\n",
        "* Most of number of views on triler is around 50."
      ],
      "metadata": {
        "id": "r_x3vN_UOpal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Genre`\n",
        "\n"
      ],
      "metadata": {
        "id": "FeLm3xp4OloY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'genre')"
      ],
      "metadata": {
        "id": "zEj-hLM0b52p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Genre of viewers is more in others.\n",
        "* Comedy is prefered by most of the people."
      ],
      "metadata": {
        "id": "qKVk29tMP222"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Day of week`"
      ],
      "metadata": {
        "id": "AFap001yOqW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'dayofweek')"
      ],
      "metadata": {
        "id": "q0zrJSh2cCiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* According to the above plot most of the movies had been watched on fridays even more than sunday.\n",
        "* second preferable day for most of the viewers is wednesday."
      ],
      "metadata": {
        "id": "zrCY8F4PQYDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Season`"
      ],
      "metadata": {
        "id": "BF9BQCHXOtrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'season')"
      ],
      "metadata": {
        "id": "NFemrQmscI_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Most common season where people prefer to watch movies is winter.\n",
        "* Later on most of the people watch movies on fall."
      ],
      "metadata": {
        "id": "fi3J30T1Q6y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Visitors`\n",
        "\n"
      ],
      "metadata": {
        "id": "3xxd9IV2PGpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'visitors',perc=True)"
      ],
      "metadata": {
        "id": "xCr6mh9TPKhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bivariate analysis"
      ],
      "metadata": {
        "id": "osVfkxrbPd7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Correlation Check"
      ],
      "metadata": {
        "id": "i4ig7QIOPiA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of numerical columns\n",
        "num_cols = data.select_dtypes(include=np.number).columns.tolist()"
      ],
      "metadata": {
        "id": "Mtq6QWGaXIMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 3))\n",
        "sns.heatmap(\n",
        "    data[num_cols].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n1HFo1b2SNNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The views of trailer and views content has high correlation which means they are highly depended on each other.\n",
        "* ad_impressions has little correlation with visitors ,views trailer and views content but has negatively correlation with major sports event.\n",
        "* major sports event has little negative correlation with visitors ,ad_impressions and views content whereas views trailer is positively correlated.\n",
        "* visitors has little correlation with ad impressions and negatively correlated with major sports event and views trailer , whereas visitors is correlated with views content.\n"
      ],
      "metadata": {
        "id": "kWdix5bXTauz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check the variation in the views content with some of the categorical columns in the data."
      ],
      "metadata": {
        "id": "ewtYxXM9PpD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Genre` vs `views content`"
      ],
      "metadata": {
        "id": "Nd_IDR2uP8Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=data,x='genre',y='views_content')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVXho-qYSVTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* View content on romance and action has more outliers"
      ],
      "metadata": {
        "id": "c0v-_2u9bc4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`day of week` vs `views content`\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YCewD-UGQE0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='dayofweek',y='views_content')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "itQbAr9NWc9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Wednesday has more views content and second largest is friday."
      ],
      "metadata": {
        "id": "cMDZnJyDbppO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`Season` vs `views_content`"
      ],
      "metadata": {
        "id": "fiAQJUrHRM8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='season',y='views_content')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "1PakxI-_W-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Views content has more on summer."
      ],
      "metadata": {
        "id": "esbwlQrvb1Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`day of week` vs` genre`\n"
      ],
      "metadata": {
        "id": "KAlmzBFoRYOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='dayofweek',y='genre')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "zyBEwvYxZxjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* On sunday thriller had been watched more"
      ],
      "metadata": {
        "id": "nQZ2rtn4SZoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`season` vs `genre`"
      ],
      "metadata": {
        "id": "IKsCSaWcRp51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='season',y='genre')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "eFWugH8pZq8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In Fall sci-fi ,thriller has watched more."
      ],
      "metadata": {
        "id": "8PaQJpBucJNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`day of week` vs `visitors`"
      ],
      "metadata": {
        "id": "9fpLoeGiRwgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='dayofweek',y='visitors')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yM2HvXxvZ5n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Visitors visits more on wednesday , friday and saturday."
      ],
      "metadata": {
        "id": "M3OUD4rzchcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`genre` vs `ad impressions`"
      ],
      "metadata": {
        "id": "hFePOZwVR1j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='genre',y='ad_impressions')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "IQ6klUcyaM5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ad_impression has more in sci-fi , horror , thriller , romance"
      ],
      "metadata": {
        "id": "zFcwvcwHc1og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`genre` vs `views trailer`"
      ],
      "metadata": {
        "id": "PYXOoB2vR7Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "sns.boxplot(data=data,x='genre',y='views_trailer')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "w88J12ooajz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In views trailer other has more outliers."
      ],
      "metadata": {
        "id": "9rh96i65dHQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "vsIZhPD0dgAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Outliers detection"
      ],
      "metadata": {
        "id": "kiG9mDYteE2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier detection using boxplot\n",
        "num_cols = data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, variable in enumerate(num_cols):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(data=data, x=variable)\n",
        "    plt.tight_layout(pad=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4bppic_AZXnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are quite a few outliers in the data\n",
        "* If we treat it will result in loss of data.\n",
        "* Outliers in the column seems to be genuine.\n",
        "* However, we will not treat them as they are proper values"
      ],
      "metadata": {
        "id": "TetxsXufegFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature engineering"
      ],
      "metadata": {
        "id": "Pm7bLSTtQSq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ad_per_visitors=ott['ad_impressions']/ott['visitors']\n",
        "print(ad_per_visitors)"
      ],
      "metadata": {
        "id": "zEJQFjj_Qgmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trailer_per_visitors=ott['views_trailer']/ott['visitors']\n",
        "print(trailer_per_visitors)"
      ],
      "metadata": {
        "id": "dj5ukhZmRP4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_ad_impression=ott['major_sports_event']*ott['ad_impressions']\n",
        "event_ad_impression"
      ],
      "metadata": {
        "id": "0EXnQZ1nRih3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1THqC335b4Yi"
      },
      "source": [
        "## Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We want to predict the views content.\n",
        "* Before we proceed to build a model, we'll have to encode categorical features\n",
        "* We'll split the data into train and test to be able to evaluate the model that we build on the train data\n",
        "* We will build a Linear Regression model using the train data and then check it's performance"
      ],
      "metadata": {
        "id": "soFSncblgeK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "# defining X and y variables\n",
        "X = data.drop([\"views_content\"], axis=1)\n",
        "y = data[\"views_content\"]\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())"
      ],
      "metadata": {
        "id": "UN3LmqYFgX1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's add the intercept to data\n",
        "X = sm.add_constant(X)"
      ],
      "metadata": {
        "id": "XxzKVk-jhRLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dummy variables\n",
        "X = pd.get_dummies(\n",
        "    X,\n",
        "    columns=X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(),\n",
        "    drop_first=True\n",
        ")\n",
        "X.head()"
      ],
      "metadata": {
        "id": "0F2uoS6ahclD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the input attributes into float type for modeling\n",
        "X = X.astype(float)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "bPvaUeYghkcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data in 70:30 ratio for train to test data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "mFzAUR6WjZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows in train data =\", x_train.shape[0])\n",
        "print(\"Number of rows in test data =\", x_test.shape[0])"
      ],
      "metadata": {
        "id": "Ht6DAlNnjoBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9_JGYY_-qUN"
      },
      "source": [
        "# Model Building - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "olsmodel = sm.OLS(y_train, x_train).fit()\n",
        "print(olsmodel.summary())"
      ],
      "metadata": {
        "id": "HjdTvqc7ka8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSK7ThIK1Le2"
      },
      "source": [
        "### Interpreting the Regression Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUO-aovo1L6i"
      },
      "source": [
        "1. **Adjusted. R-squared**: It reflects the fit of the model.\n",
        "    - Adjusted R-squared values generally range from 0 to 1, where a higher value generally indicates a better fit, assuming certain conditions are met.\n",
        "    - In our case, the value for adj. R-squared is **0.785**, which is good.\n",
        "\n",
        "\n",
        "2. ***const* coefficient**: It is the Y-intercept.\n",
        "    - It means that if all the predictor variable coefficients are zero, then the expected output (i.e., Y) would be equal to the *const* coefficient.\n",
        "    - In our case, the value for `const` coefficient is **0.0602**\n",
        "\n",
        "\n",
        "3. **Coefficient of a predictor variable**: It represents the change in the output Y due to a change in the predictor variable (everything else held constant).\n",
        "    - In our case, the coefficient of `duration` is **0.0123**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhWcTffM-qUN"
      },
      "source": [
        "### Model Performance Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7pUm3x-qUN"
      },
      "source": [
        "Let's check the performance of the model using different metrics.\n",
        "\n",
        "* We will be using metric functions defined in sklearn for RMSE, MAE, and $R^2$.\n",
        "* We will define a function to calculate MAPE and adjusted $R^2$.\n",
        "    - The mean absolute percentage error (MAPE) measures the accuracy of predictions as a percentage, and can be calculated as the average absolute percent error for each predicted value minus actual values divided by actual values. It works best if there are no extreme values in the data and none of the actual values are 0.\n",
        "    \n",
        "* We will create a function which will print out all the above metrics in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deaapIIvlJIL"
      },
      "outputs": [],
      "source": [
        "# function to compute adjusted R-squared\n",
        "def adj_r2_score(predictors, targets, predictions):\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "# function to compute MAPE\n",
        "def mape_score(targets, predictions):\n",
        "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
        "\n",
        "\n",
        "# function to compute different metrics to check performance of a regression model\n",
        "def model_performance_regression(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check regression model performance\n",
        "\n",
        "    model: regressor\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    r2 = r2_score(target, pred)  # to compute R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
        "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
        "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
        "    mape = mape_score(target, pred)  # to compute MAPE\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"R-squared\": r2,\n",
        "            \"Adj. R-squared\": adjr2,\n",
        "            \"MAPE\": mape,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVBBaPtf-BZd"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmodel_train_perf = model_performance_regression(olsmodel, x_train, y_train)\n",
        "olsmodel_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv51vNBhlJIL"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmodel_test_perf = model_performance_regression(olsmodel, x_test, y_test)\n",
        "olsmodel_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQ3kqwZ-qUO"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- The training $R^2$ is 0.72, so the model is not underfitting\n",
        "\n",
        "- The train and test RMSE and MAE are comparable, so the model is not overfitting either\n",
        "\n",
        "- MAE suggests that the model can predict anime ratings within a mean error of 0.34 on the test data\n",
        "\n",
        "- MAPE of 12.6 on the test data means that we are able to predict within 12.6% of the anime ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9GxSQf-qH8e"
      },
      "source": [
        "#Checking Linear Regression Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wr6XkwoqH8f"
      },
      "source": [
        "We will be checking the following Linear Regression assumptions:\n",
        "\n",
        "1. **No Multicollinearity**\n",
        "\n",
        "2. **Linearity of variables**\n",
        "\n",
        "3. **Independence of error terms**\n",
        "\n",
        "4. **Normality of error terms**\n",
        "\n",
        "5. **No Heteroscedasticity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mROHQdzZqH8f"
      },
      "source": [
        "### TEST FOR MULTICOLLINEARITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul6gKpZqIZ6M"
      },
      "source": [
        "* Multicollinearity occurs when predictor variables in a regression model are correlated. This correlation is a problem because predictor variables should be independent. If the correlation between variables is high, it can cause problems when we fit the model and interpret the results. When we have multicollinearity in the linear model, the coefficients that the model suggests are unreliable.\n",
        "\n",
        "* There are different ways of detecting (or testing) multicollinearity. One such way is by using the Variance Inflation Factor, or VIF.\n",
        "\n",
        "* **Variance  Inflation Factor (VIF)**:  Variance inflation factors measure the inflation in the variances of the regression parameter estimates due to collinearities that exist among the predictors. It is a measure of how much the variance of the estimated regression coefficient $\\beta_k$ is \"inflated\" by the existence of correlation among the predictor variables in the model.\n",
        "    - If VIF is 1, then there is no correlation among the $k$th predictor and the remaining predictor variables, and hence, the variance of $\\beta_k$ is not inflated at all.\n",
        "\n",
        "* **General Rule of thumb**:\n",
        "    - If VIF is between 1 and 5, then there is low multicollinearity.\n",
        "    - If VIF is between 5 and 10, we say there is moderate multicollinearity.\n",
        "    - If VIF is exceeding 10, it shows signs of high multicollinearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6sSyDfqVR3"
      },
      "source": [
        "Let's define a function to check VIF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV-69rVWqH8g"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "def checking_vif(predictors):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"feature\"] = predictors.columns\n",
        "\n",
        "    # calculating VIF for each feature\n",
        "    vif[\"VIF\"] = [\n",
        "        variance_inflation_factor(predictors.values, i)\n",
        "        for i in range(len(predictors.columns))\n",
        "    ]\n",
        "    return vif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC7xu368-qUO"
      },
      "outputs": [],
      "source": [
        "checking_vif(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtalwdoE-qUP"
      },
      "source": [
        "* There are zero columns with very high VIF values, indicating presence of strong multicollinearity\n",
        "* We would systematically drop numerical columns if we had VIF > 5\n",
        "* We will ignore the VIF values for dummy variables and the constant (intercept)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM0uBl1o3UDi"
      },
      "source": [
        "### Interpreting the Regression Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnjQ09Rk3LWk"
      },
      "source": [
        "4. **std err**: It reflects the level of accuracy of the coefficients.\n",
        "    - The lower it is, the higher is the level of accuracy.\n",
        "\n",
        "\n",
        "5. **P>|t|**: It is p-value.\n",
        "   \n",
        "    * For each independent feature, there is a null hypothesis and an alternate hypothesis. Here $\\beta_i$ is the coefficient of the $i$th independent variable.\n",
        "\n",
        "        - $H_o$ : Independent feature is not significant ($\\beta_i = 0$)\n",
        "        - $H_a$ : Independent feature is that it is significant ($\\beta_i \\neq 0$)\n",
        "\n",
        "    * (P>|t|) gives the p-value for each independent feature to check that null hypothesis. We are considering 0.05 (5%) as significance level.\n",
        "        \n",
        "        - A p-value of less than 0.05 is considered to be statistically significant.\n",
        "\n",
        "\n",
        "6. **Confidence Interval**: It represents the range in which our coefficients are likely to fall (with a likelihood of 95%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugvIKXJB-qUS"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- As there is no multicollinearity, we can look at the p-values of predictor variables to check their significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccsFJFYoqH9J"
      },
      "source": [
        "### Dealing with high p-value variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0CO6CS4jYF"
      },
      "source": [
        "- Some of the dummy variables in the data have p-value > 0.05. So, they are not significant and we'll drop them\n",
        "- But sometimes p-values change after dropping a variable. So, we'll not drop all variables at once\n",
        "- Instead, we will do the following:\n",
        "    - Build a model, check the p-values of the variables, and drop the column with the highest p-value\n",
        "    - Create a new model without the dropped feature, check the p-values of the variables, and drop the column with the highest p-value\n",
        "    - Repeat the above two steps till there are no columns with p-value > 0.05\n",
        "\n",
        "**Note**: The above process can also be done manually by picking one variable at a time that has a high p-value, dropping it, and building a model again. But that might be a little tedious and using a loop will be more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFkO5oFj-qUT"
      },
      "outputs": [],
      "source": [
        "# initial list of columns\n",
        "predictors = x_train.copy()\n",
        "cols = predictors.columns.tolist()\n",
        "\n",
        "# setting an initial max p-value\n",
        "max_p_value = 1\n",
        "\n",
        "while len(cols) > 0:\n",
        "    # defining the train set\n",
        "    x_train_aux = predictors[cols]\n",
        "\n",
        "    # fitting the model\n",
        "    model = sm.OLS(y_train, x_train_aux).fit()\n",
        "\n",
        "    # getting the p-values and the maximum p-value\n",
        "    p_values = model.pvalues\n",
        "    max_p_value = max(p_values)\n",
        "\n",
        "    # name of the variable with maximum p-value\n",
        "    feature_with_p_max = p_values.idxmax()\n",
        "\n",
        "    if max_p_value > 0.05:\n",
        "        cols.remove(feature_with_p_max)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "selected_features = cols\n",
        "print(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4fj6umDqH9N"
      },
      "outputs": [],
      "source": [
        "x_train2= x_train[selected_features]\n",
        "x_test2= x_test[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCDUCG6_qH9R"
      },
      "outputs": [],
      "source": [
        "olsmod2 = sm.OLS(y_train, x_train2).fit()\n",
        "print(olsmod2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nfdyeTW4Ilk"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmod2_train_perf = model_performance_regression(olsmod2, x_train2, y_train)\n",
        "olsmod2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3azyApn44Ilk"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmod2_test_perf = model_performance_regression(olsmod2, x_test2, y_test)\n",
        "olsmod2_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85AyhdAfqH9z"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "* Now no feature has p-value greater than 0.05, so we'll consider the features in *x_train2* as the final set of predictor variables and *olsmod2* as the final model to move forward with\n",
        "* Now adjusted R-squared is 0.7483, i.e., our model is able to explain ~75% of the variance\n",
        "* The adjusted R-squared in *olsmod* (where we considered the variables without multicollinearity) was 0.749\n",
        "    * This shows that the variables we dropped were not affecting the model\n",
        "* RMSE and MAE values are comparable for train and test sets, indicating that the model is not overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctk29PsRqH90"
      },
      "source": [
        "**Now we'll check the rest of the assumptions on *olsmod2*.**\n",
        "\n",
        "2. **Linearity of variables**\n",
        "\n",
        "3. **Independence of error terms**\n",
        "\n",
        "4. **Normality of error terms**\n",
        "\n",
        "5. **No Heteroscedasticity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnOY6E5uqH-C"
      },
      "source": [
        "### TEST FOR LINEARITY AND INDEPENDENCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlczpHheIOEX"
      },
      "source": [
        "**Why the test?**\n",
        "\n",
        "* Linearity describes a straight-line relationship between two variables, predictor variables must have a linear relation with the dependent variable.\n",
        "* The independence of the error terms (or residuals) is important. If the residuals are not independent, then the confidence intervals of the coefficient estimates will be narrower and make us incorrectly conclude a parameter to be statistically significant.\n",
        "\n",
        "**How to check linearity and independence?**\n",
        "\n",
        "- Make a plot of fitted values vs residuals.\n",
        "- If they don't follow any pattern, then we say the model is linear and residuals are independent.\n",
        "- Otherwise, the model is showing signs of non-linearity and residuals are not independent.\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* We can try to transform the variables and make the relationships linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgyzF2ii-qUT"
      },
      "outputs": [],
      "source": [
        "# let us create a dataframe with actual, fitted and residual values\n",
        "df_pred = pd.DataFrame()\n",
        "\n",
        "df_pred[\"Actual Values\"] = y_train  # actual values\n",
        "df_pred[\"Fitted Values\"] = olsmod2.fittedvalues  # predicted values\n",
        "df_pred[\"Residuals\"] = olsmod2.resid  # residuals\n",
        "\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ4ivHQiqH-G"
      },
      "outputs": [],
      "source": [
        "# let's plot the fitted values vs residuals\n",
        "\n",
        "sns.residplot(\n",
        "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
        ")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Fitted vs Residual plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdVdvRegqH-M"
      },
      "source": [
        "* The scatter plot shows the distribution of residuals (errors) vs fitted values (predicted values).\n",
        "\n",
        "* If there exist any pattern in this plot, we consider it as signs of non-linearity in the data and a pattern means that the model doesn't capture non-linear effects.\n",
        "\n",
        "* **We see no pattern in the plot above. Hence, the assumptions of linearity and independence are satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOxf_qsQqH-N"
      },
      "source": [
        "### TEST FOR NORMALITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9VQtrfXIIIE"
      },
      "source": [
        "**Why the test?**\n",
        "\n",
        "* Error terms, or residuals, should be normally distributed. If the error terms are not normally distributed, confidence intervals of the coefficient estimates may become too wide or narrow. Once confidence interval becomes unstable, it leads to difficulty in estimating coefficients based on minimization of least squares. Non-normality suggests that there are a few unusual data points that must be studied closely to make a better model.\n",
        "\n",
        "**How to check normality?**\n",
        "\n",
        "* The shape of the histogram of residuals can give an initial idea about the normality.\n",
        "* It can also be checked via a Q-Q plot of residuals. If the residuals follow a normal distribution, they will make a straight line plot, otherwise not.\n",
        "* Other tests to check for normality includes the Shapiro-Wilk test.\n",
        "    - Null hypothesis: Residuals are normally distributed\n",
        "    - Alternate hypothesis: Residuals are not normally distributed\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* We can apply transformations like log, exponential, arcsinh, etc. as per our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUdQ6XJLqH-N"
      },
      "outputs": [],
      "source": [
        "#residuals normality check\n",
        "sns.histplot(data=df_pred, x=\"Residuals\", kde=True)\n",
        "plt.title(\"Normality of residuals\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9YQpkZ-qH-Q"
      },
      "source": [
        "- The histogram of residuals does have a bell shape.\n",
        "- Let's check the Q-Q plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj8y7-1nqH-Q"
      },
      "outputs": [],
      "source": [
        "#Probability plot\n",
        "import pylab\n",
        "import scipy.stats as stats\n",
        "\n",
        "stats.probplot(df_pred[\"Residuals\"], dist=\"norm\", plot=pylab)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKlOF0TT-qUV"
      },
      "source": [
        "- The residuals more or less follow a straight line except for the tails.\n",
        "- Let's check the results of the Shapiro-Wilk test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1LIATpBqH-U"
      },
      "outputs": [],
      "source": [
        "stats.shapiro(df_pred[\"Residuals\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD0BLsvSqH-Z"
      },
      "source": [
        "- Since p-value < 0.05, the residuals are not normal as per the Shapiro-Wilk test.\n",
        "- Strictly speaking, the residuals are not normal.\n",
        "- However, as an approximation, we can accept this distribution as close to being normal.\n",
        "- **So, the assumption is satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZ4GKY_qH-Z"
      },
      "source": [
        "### TEST FOR HOMOSCEDASTICITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyJPcnJYIDJQ"
      },
      "source": [
        "* **Homoscedascity**: If the variance of the residuals is symmetrically distributed across the regression line, then the data is said to be homoscedastic.\n",
        "\n",
        "* **Heteroscedascity**: If the variance is unequal for the residuals across the regression line, then the data is said to be heteroscedastic.\n",
        "\n",
        "**Why the test?**\n",
        "\n",
        "* The presence of non-constant variance in the error terms results in heteroscedasticity. Generally, non-constant variance arises in presence of outliers.\n",
        "\n",
        "**How to check for homoscedasticity?**\n",
        "\n",
        "* The residual vs fitted values plot can be looked at to check for homoscedasticity. In the case of heteroscedasticity, the residuals can form an arrow shape or any other non-symmetrical shape.\n",
        "* The goldfeldquandt test can also be used. If we get a p-value > 0.05 we can say that the residuals are homoscedastic. Otherwise, they are heteroscedastic.\n",
        "    - Null hypothesis: Residuals are homoscedastic\n",
        "    - Alternate hypothesis: Residuals have heteroscedasticity\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* Heteroscedasticity can be fixed by adding other important features or making transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naX-iXItqH-b"
      },
      "outputs": [],
      "source": [
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "\n",
        "name = [\"F statistic\", \"p-value\"]\n",
        "test = sms.het_goldfeldquandt(df_pred[\"Residuals\"], x_train2)\n",
        "lzip(name, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmt1AqYqH-d"
      },
      "source": [
        "**Since p-value > 0.05, we can say that the residuals are homoscedastic. So, this assumption is satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M24kMcA-qUW"
      },
      "source": [
        "# Predictions on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbnr4QViqH-e"
      },
      "source": [
        "Now that we have checked all the assumptions of linear regression and they are satisfied, let's go ahead with prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAtayJx4Ge75"
      },
      "outputs": [],
      "source": [
        "# predictions on the test set\n",
        "pred = olsmod2.predict(x_test2)\n",
        "\n",
        "df_pred_test = pd.DataFrame({\"Actual\": y_test, \"Predicted\": pred})\n",
        "df_pred_test.sample(10, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KXrJHtFJvEu"
      },
      "source": [
        "- We can observe here that our model has returned pretty good prediction results, and the actual and predicted values are comparable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-G8CObN-qUX"
      },
      "source": [
        "#Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpEdqajh-qUX"
      },
      "source": [
        "Let's recreate the final model and print it's summary to gain insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxtxD00o557M"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train2.copy()\n",
        "x_test_final = x_test2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDZD9zkmqH-x"
      },
      "outputs": [],
      "source": [
        "olsmodel_final = sm.OLS(y_train, x_train_final).fit()\n",
        "print(olsmodel_final.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCKvjTcd-qUX"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmodel_final_train_perf = model_performance_regression(\n",
        "    olsmodel_final, x_train_final, y_train\n",
        ")\n",
        "olsmodel_final_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkjC-WAb-qUZ"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmodel_final_test_perf = model_performance_regression(\n",
        "    olsmodel_final, x_test_final, y_test\n",
        ")\n",
        "olsmodel_final_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8CeR5BuqH-w"
      },
      "source": [
        "* The model is able to explain ~75% of the variation in the data\n",
        "\n",
        "* The train and test RMSE and MAE are low and comparable. So, our model is not suffering from overfitting\n",
        "\n",
        "* The MAPE on the test set suggests we can predict within 9.38% of the views content\n",
        "\n",
        "* Hence, we can conclude the model *olsmodel_final* is good for prediction as well as inference purposes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvDRg5b-qUZ"
      },
      "source": [
        "#Conclusions and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aXG5ChnU-MW"
      },
      "source": [
        "1. The model is able to explain ~75% of the variation in the data and within 9.38% of the views content on the test data, which is good\n",
        "    - This indicates that the model is good for prediction as well as inference purposes\n",
        "\n",
        "\n",
        "2. If the visitors of view content increases by one unit, then its view increases by 0.0729 units, all other variables held constant\n",
        "\n",
        "\n",
        "3. If the major sports event increases by one unit, then its views decreases 0.069 by  units, all other variables held constant\n",
        "\n",
        "\n",
        "4. If the views of the trailer increases by one unit, then its views increases by 0.0023 units, all other variables held constant\n",
        "\n",
        "\n",
        "5. The views on content on saturday increases, then its view increases by 0.0582 units.\n",
        "\n",
        "\n",
        "6. As the views content increase with an increase in the number of visitors, the company can improve its marketing activities to promote their content\n",
        "\n",
        "\n",
        "7. As the views content increase with an decrease in major sports event.\n",
        "\n",
        "\n",
        "8. Streamist can look to increase the number of content under the Drama , Horror ,Sci-fi genres as they are the most watched on the platform.\n",
        "\n",
        "\n",
        "9. Streamist can gather data about their users like age, gender, geographical location, occupation, etc. to better understand the kind of web series and movies different users like"
      ]
    }
  ]
}